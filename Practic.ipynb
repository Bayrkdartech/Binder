{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bayrkdartech/Binder/blob/main/Practic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "HbJ4h6QPx5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac022fbf-f916-4204-dd84-5546318caf60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Dataset URL: https://www.kaggle.com/datasets/robikscube/hourly-energy-consumption\n",
            "License(s): CC0-1.0\n",
            "hourly-energy-consumption.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "Archive:  hourly-energy-consumption.zip\n",
            "replace data/AEP_hourly.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: data/AEP_hourly.csv     \n",
            "  inflating: data/COMED_hourly.csv   \n",
            "  inflating: data/DAYTON_hourly.csv  \n",
            "  inflating: data/DEOK_hourly.csv    \n",
            "  inflating: data/DOM_hourly.csv     \n",
            "  inflating: data/DUQ_hourly.csv     \n",
            "  inflating: data/EKPC_hourly.csv    \n",
            "  inflating: data/FE_hourly.csv      \n",
            "  inflating: data/NI_hourly.csv      \n",
            "  inflating: data/PJME_hourly.csv    \n",
            "  inflating: data/PJMW_hourly.csv    \n",
            "  inflating: data/PJM_Load_hourly.csv  \n",
            "  inflating: data/est_hourly.paruqet  \n",
            "  inflating: data/pjm_hourly_est.csv  \n",
            "PJME_MW    0\n",
            "dtype: int64\n",
            "Empty DataFrame\n",
            "Columns: [PJME_MW]\n",
            "Index: []\n",
            "0 قيم المفقودة:\n",
            "3455 القيم الشادة\n",
            "قيم الشادة :\n",
            " Datetime\n",
            "2002-08-22 16:00:00    48285.0\n",
            "2002-08-22 17:00:00    48587.0\n",
            "2002-08-22 18:00:00    48302.0\n",
            "2002-08-20 14:00:00    48052.0\n",
            "2002-08-20 15:00:00    48656.0\n",
            "2002-08-20 16:00:00    48951.0\n",
            "2002-08-20 17:00:00    49130.0\n",
            "2002-08-20 18:00:00    48639.0\n",
            "2002-08-19 12:00:00    48980.0\n",
            "2002-08-19 13:00:00    50712.0\n",
            "Name: PJME_MW, dtype: float64\n",
            "تم تعديل القيم الشادة بواسطة الوسيط\n",
            "قيم الشادة :\n",
            " Datetime\n",
            "2002-08-22 16:00:00    31421.0\n",
            "2002-08-22 17:00:00    31421.0\n",
            "2002-08-22 18:00:00    31421.0\n",
            "2002-08-20 14:00:00    31421.0\n",
            "2002-08-20 15:00:00    31421.0\n",
            "2002-08-20 16:00:00    31421.0\n",
            "2002-08-20 17:00:00    31421.0\n",
            "2002-08-20 18:00:00    31421.0\n",
            "2002-08-19 12:00:00    31421.0\n",
            "2002-08-19 13:00:00    31421.0\n",
            "Name: PJME_MW, dtype: float64\n",
            "Datetime\n",
            "2002-10-27 03:00:00     0 days 02:00:00\n",
            "2002-04-07 04:00:00     0 days 02:00:00\n",
            "2003-12-31 01:00:00   728 days 01:00:00\n",
            "2003-10-26 03:00:00     0 days 02:00:00\n",
            "2003-04-06 04:00:00     0 days 02:00:00\n",
            "2004-12-31 01:00:00   729 days 01:00:00\n",
            "2004-10-31 03:00:00     0 days 02:00:00\n",
            "2004-04-04 04:00:00     0 days 02:00:00\n",
            "2005-12-31 01:00:00   729 days 01:00:00\n",
            "2005-10-30 03:00:00     0 days 02:00:00\n",
            "2005-04-03 04:00:00     0 days 02:00:00\n",
            "2006-12-31 01:00:00   728 days 01:00:00\n",
            "2006-10-29 03:00:00     0 days 02:00:00\n",
            "2006-04-02 04:00:00     0 days 02:00:00\n",
            "2007-12-31 01:00:00   728 days 01:00:00\n",
            "2007-11-04 03:00:00     0 days 02:00:00\n",
            "2007-03-11 04:00:00     0 days 02:00:00\n",
            "2008-12-31 01:00:00   729 days 01:00:00\n",
            "2008-11-02 03:00:00     0 days 02:00:00\n",
            "2008-03-09 04:00:00     0 days 02:00:00\n",
            "2009-12-31 01:00:00   729 days 01:00:00\n",
            "2009-11-01 03:00:00     0 days 02:00:00\n",
            "2009-03-08 04:00:00     0 days 02:00:00\n",
            "2010-12-31 01:00:00   728 days 01:00:00\n",
            "2010-11-07 03:00:00     0 days 02:00:00\n",
            "2010-03-14 04:00:00     0 days 02:00:00\n",
            "2011-12-31 01:00:00   728 days 01:00:00\n",
            "2011-11-06 03:00:00     0 days 02:00:00\n",
            "2011-03-13 04:00:00     0 days 02:00:00\n",
            "2012-12-31 01:00:00   729 days 01:00:00\n",
            "2012-11-04 03:00:00     0 days 02:00:00\n",
            "2012-03-11 04:00:00     0 days 02:00:00\n",
            "2013-12-31 01:00:00   729 days 01:00:00\n",
            "2013-11-03 03:00:00     0 days 02:00:00\n",
            "2013-03-10 04:00:00     0 days 02:00:00\n",
            "2014-12-31 01:00:00   728 days 01:00:00\n",
            "2014-03-09 04:00:00     0 days 02:00:00\n",
            "2015-12-31 01:00:00   728 days 01:00:00\n",
            "2015-03-08 04:00:00     0 days 02:00:00\n",
            "2016-12-31 01:00:00   729 days 01:00:00\n",
            "2016-03-13 04:00:00     0 days 02:00:00\n",
            "2017-12-31 01:00:00   729 days 01:00:00\n",
            "2017-03-12 04:00:00     0 days 02:00:00\n",
            "2018-08-02 01:00:00   577 days 01:00:00\n",
            "2018-03-11 04:00:00     0 days 02:00:00\n",
            "Name: Datetime, dtype: timedelta64[ns]\n",
            "الفجوات الزمنية الكبيرة :\n",
            "                      PJME_MW           get_gap\n",
            "Datetime                                      \n",
            "2002-12-31 01:00:00  26498.0               NaT\n",
            "2003-12-31 01:00:00  27525.0 728 days 01:00:00\n",
            "2004-12-31 01:00:00  27160.0 729 days 01:00:00\n",
            "2005-12-31 01:00:00  28916.0 729 days 01:00:00\n",
            "2006-12-31 01:00:00  26870.0 728 days 01:00:00\n",
            "2007-12-31 01:00:00  28289.0 728 days 01:00:00\n",
            "2008-12-31 01:00:00  28937.0 729 days 01:00:00\n",
            "2009-12-31 01:00:00  31429.0 729 days 01:00:00\n",
            "2010-12-31 01:00:00  29634.0 728 days 01:00:00\n",
            "2011-12-31 01:00:00  26186.0 728 days 01:00:00\n",
            "2012-12-31 01:00:00  29893.0 729 days 01:00:00\n",
            "2013-12-31 01:00:00  30254.0 729 days 01:00:00\n",
            "2014-12-31 01:00:00  30795.0 728 days 01:00:00\n",
            "2015-12-31 01:00:00  24305.0 728 days 01:00:00\n",
            "2016-12-31 01:00:00  29627.0 729 days 01:00:00\n",
            "2017-12-31 01:00:00  35242.0 729 days 01:00:00\n",
            "2018-08-02 01:00:00  34283.0 577 days 01:00:00\n",
            "عدد القيم المفقودة بعد التعبئة   0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# استيراد المكتبات\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# 1. توصيل Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. إنشاء مجلد للكاجل داخل Colab\n",
        "!mkdir -p ~/.kaggle\n",
        "\n",
        "# 3. نسخ ملف kaggle.json من Google Drive إلى مجلد الكاجل\n",
        "# غيّر هذا المسار حسب مكان ملف kaggle.json في Drive\n",
        "!cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
        "\n",
        "# 4. ضبط الأذونات\n",
        "!chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# 5. تحميل بيانات من Kaggle\n",
        "# مثال: تحميل Dataset الطاقة \"Hourly Energy Consumption\"\n",
        "!kaggle datasets download -d robikscube/hourly-energy-consumption\n",
        "\n",
        "# 6. فك الضغط عن البيانات\n",
        "!unzip hourly-energy-consumption.zip -d data/\n",
        "\n",
        "# 7. قراءة الملف باستخدام Pandas\n",
        "import pandas as pd\n",
        "\n",
        "# مثال: قراءة ملف PJME_hourly.csv\n",
        "df = pd.read_csv('data/PJME_hourly.csv')\n",
        "\n",
        "# عرض أول 5 صفوف\n",
        "\n",
        "\n",
        "##first step ##### we turned the string to datetime\n",
        "\n",
        "df['Datetime']= pd.to_datetime(df['Datetime'])\n",
        "df.sort_values('Datetime')\n",
        "df.set_index('Datetime', inplace=True)\n",
        "df.resample('h').mean()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(df.isna().sum())\n",
        "df.dropna().sum()\n",
        "\n",
        "# عرض القيم المكررة نفسها\n",
        "df=df[~df.index.duplicated(keep='first')]\n",
        "duplicates= df[df.index.duplicated(keep=False)]\n",
        "print(duplicates)\n",
        "\n",
        "print(df.isna().sum().sum(),'قيم المفقودة:')\n",
        "\n",
        "\n",
        "###### --  outliers -- ####\n",
        "\n",
        "\n",
        "q1= df['PJME_MW'].quantile(0.25)\n",
        "q3= df['PJME_MW'].quantile(0.75)\n",
        "iqr= q3 - q1\n",
        "outliers= df[(df['PJME_MW'] < q1 - 1.5 * iqr) | (df['PJME_MW']> q3 + 1.5 * iqr)]\n",
        "print(len(outliers),\"القيم الشادة\")\n",
        "\n",
        "#عرض اول 10 قيم شادة قبل تعديل\n",
        "print(\"قيم الشادة :\\n\", df.loc[outliers.index,'PJME_MW'].head(10))\n",
        "\n",
        "#تعديل قيم الشادة\n",
        "df_modified= df.copy()\n",
        "median_values= df['PJME_MW'].median()\n",
        "df_modified.loc[outliers.index,'PJME_MW']=median_values\n",
        "print('تم تعديل القيم الشادة بواسطة الوسيط')\n",
        "\n",
        "#عرض قسم الشادة بعد تعديل\n",
        "print(\"قيم الشادة :\\n\", df_modified.loc[outliers.index, 'PJME_MW'].head(10))\n",
        "# اكتشاف فجوات زمنية\n",
        "Azez_diff=pd.Timedelta(hours=1)\n",
        "time_diff= df.index.to_series().diff()\n",
        "# عرض الفجزات كبيرة\n",
        "gabs=time_diff[time_diff> Azez_diff]\n",
        "print(gabs)\n",
        "# تصنيف الفجوة باستخدام دالة الشركة if\n",
        "df['get_gap']= time_diff\n",
        "df['gap_type']= df['get_gap'].apply(lambda x: 'normal' if x== Azez_diff\n",
        "else ('small gap' if x< pd.Timedelta(days= 1)\n",
        "else 'larg_gap')\n",
        "\n",
        ")\n",
        "\n",
        "#  عرض فجوات كبيرة\n",
        "larg_gap= df[df['gap_type']== 'larg_gap']\n",
        "print(\"الفجوات الزمنية الكبيرة :\\n\", larg_gap[['PJME_MW', 'get_gap']])\n",
        "df.head()\n",
        "\n",
        "# fill the large time gaps\n",
        "df.index=pd.to_datetime(df.index)\n",
        "\n",
        "full_index=pd.date_range(start=df.index.min(), end=df.index.max(), freq='h')\n",
        "df= df.reindex(full_index)\n",
        "df['PJME_MW']= df['PJME_MW'].ffill().bfill()\n",
        "#print the result after fill in by previous result\n",
        "\n",
        "print(\"عدد القيم المفقودة بعد التعبئة  \", df['PJME_MW'].isna().sum())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP505EYk6tWCFDIXxGD4G8f",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}