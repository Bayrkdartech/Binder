{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bayrkdartech/Binder/blob/main/PMJE_MW.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "HbJ4h6QPx5Zb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6569b1cb-dc81-4482-b055-04f35e63856e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "ğŸ“‚ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙ„Ù† ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„.\n",
            "âœ… Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙÙƒÙˆÙƒØ© Ù…Ø³Ø¨Ù‚Ù‹Ø§.\n",
            "Ø£ÙˆÙ„ 5 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\n",
            "              Datetime   AEP_MW\n",
            "0  2004-12-31 01:00:00  13478.0\n",
            "1  2004-12-31 02:00:00  12865.0\n",
            "2  2004-12-31 03:00:00  12577.0\n",
            "3  2004-12-31 04:00:00  12517.0\n",
            "4  2004-12-31 05:00:00  12670.0\n",
            "Datetime    0\n",
            "AEP_MW      0\n",
            "dtype: int64\n",
            "                      AEP_MW\n",
            "Datetime                    \n",
            "2014-11-02 02:00:00  12994.0\n",
            "2014-11-02 02:00:00  13190.0\n",
            "2015-11-01 02:00:00  10785.0\n",
            "2015-11-01 02:00:00  10542.0\n",
            "2016-11-06 02:00:00  10964.0\n",
            "2016-11-06 02:00:00  11008.0\n",
            "2017-11-05 02:00:00  10596.0\n",
            "2017-11-05 02:00:00  10446.0\n",
            "The duplicated: 0\n"
          ]
        }
      ],
      "source": [
        "# Ø§Ø³ØªÙŠØ±Ø§Ø¯ Ø§Ù„Ù…ÙƒØªØ¨Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from scipy.stats import ttest_ind\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# 1. ØªÙˆØµÙŠÙ„ Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# 2. Ø¥Ø¹Ø¯Ø§Ø¯ Ù…Ø¬Ù„Ø¯ kaggle\n",
        "os.makedirs(\"/root/.kaggle\", exist_ok=True)\n",
        "\n",
        "# 3. Ù†Ø³Ø® Ù…Ù„Ù kaggle.json Ù…Ù† Google Drive Ø¥Ù„Ù‰ Ù…Ø¬Ù„Ø¯ kaggle\n",
        "# ØºÙŠÙ‘Ø± Ø§Ù„Ù…Ø³Ø§Ø± Ø¥Ø°Ø§ Ù…Ù„Ù kaggle.json Ù…ÙˆØ¬ÙˆØ¯ Ø¨Ù…ÙƒØ§Ù† Ø¢Ø®Ø±\n",
        "!cp /content/drive/MyDrive/kaggle.json /root/.kaggle/\n",
        "\n",
        "# 4. Ø¶Ø¨Ø· Ø§Ù„Ø£Ø°ÙˆÙ†Ø§Øª\n",
        "!chmod 600 /root/.kaggle/kaggle.json\n",
        "\n",
        "# 5. Ø¥Ù†Ø´Ø§Ø¡ Ù…Ø¬Ù„Ø¯ data Ø¥Ø°Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯\n",
        "os.makedirs(\"data\", exist_ok=True)\n",
        "\n",
        "# 6. ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ù…Ù† Kaggle Ø¥Ø°Ø§ ØºÙŠØ± Ù…ÙˆØ¬ÙˆØ¯Ø©\n",
        "if not os.path.exists(\"data/hourly-energy-consumption.zip\"):\n",
        "    !kaggle datasets download -d robikscube/hourly-energy-consumption -p data -q\n",
        "else:\n",
        "    print(\"ğŸ“‚ Ø§Ù„Ù…Ù„Ù Ù…ÙˆØ¬ÙˆØ¯ Ù…Ø³Ø¨Ù‚Ù‹Ø§ ÙˆÙ„Ù† ÙŠØªÙ… Ø¥Ø¹Ø§Ø¯Ø© Ø§Ù„ØªØ­Ù…ÙŠÙ„.\")\n",
        "\n",
        "# 7. ÙÙƒ Ø§Ù„Ø¶ØºØ· (Ø¨Ø¯ÙˆÙ† Ø±Ø³Ø§Ø¦Ù„)\n",
        "if not os.path.exists(\"data/AEP_hourly.csv\"):  # Ù†ØªØ£ÙƒØ¯ Ø¥Ø°Ø§ ØªÙÙƒ Ø§Ù„Ø¶ØºØ· Ø³Ø§Ø¨Ù‚Ù‹Ø§\n",
        "    !unzip -q data/hourly-energy-consumption.zip -d data\n",
        "else:\n",
        "    print(\"âœ… Ø§Ù„Ù…Ù„ÙØ§Øª Ù…ÙÙƒÙˆÙƒØ© Ù…Ø³Ø¨Ù‚Ù‹Ø§.\")\n",
        "\n",
        "# 8. Ù‚Ø±Ø§Ø¡Ø© Ù…Ù„Ù CSV Ù…Ø«Ø§Ù„\n",
        "df = pd.read_csv(\"data/AEP_hourly.csv\")\n",
        "print(\"Ø£ÙˆÙ„ 5 ØµÙÙˆÙ Ù…Ù† Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:\")\n",
        "print(df.head())\n",
        "\n",
        "\n",
        "# FIRST STEP ### Exlore the missing values\n",
        "\n",
        "print(df.isna().sum())\n",
        "\n",
        "# step 2 #### turn the column to datetimeindex\n",
        "df['Datetime']= pd.to_datetime(df['Datetime'])\n",
        "df.sort_values('Datetime')\n",
        "df.set_index('Datetime', inplace= True)\n",
        "df.resample('h').mean()\n",
        "\n",
        "#Step 3 ### Explore the duplicated values\n",
        "duplicated= df[df.index.duplicated(keep=False )]\n",
        "\n",
        "print(duplicated)\n",
        "\n",
        "df=df[~df.index.duplicated(keep='first')]\n",
        "print('The duplicated:',df.index.duplicated().sum())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMtaqNWy4ku/seFrbcPuM3P",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}